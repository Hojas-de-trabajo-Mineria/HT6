---
title: "HT7"
format: html
editor: visual
---

# Hoja de Trabajo 7

```{r include=FALSE}

library(psych)
library(dplyr)
library(ggplot2)
library(reshape2)
library(psych)
library(corrplot)
library(RColorBrewer)
library(nortest)
library(lmtest)
library(jtools)
library(rpart)
library(rpart.plot)
library(caret)
library(e1071)
library(randomForest)

pricesTrain <- read.csv("train.csv")
```

## Modificación de los datos

```{r mod_datos}
colSums(is.na(pricesTrain))

orderPrice <- pricesTrain[order(pricesTrain$SalePrice),]
orderPrice['Clasificacion']<- list(1:nrow(orderPrice))
orderPrice <- orderPrice %>% select(-c(Id, MoSold, YrSold, GarageYrBlt, Alley, LotShape, LandContour, Condition2, YearBuilt, Exterior2nd, FireplaceQu, GarageQual, SaleType,BsmtFinType2, BsmtFinSF2, BsmtUnfSF, BsmtFullBath, BsmtHalfBath, X3SsnPorch, GarageFinish, YearRemodAdd, PoolQC, Fence, MiscFeature))

orderPrice <- orderPrice %>% mutate_at (c("MSSubClass","MSZoning", "Utilities", "LotConfig", "Street", "LandSlope", "Neighborhood", "Condition1", "BldgType", "HouseStyle", "OverallQual", "OverallCond", "RoofStyle", "PavedDrive", "RoofMatl", "Exterior1st", "MasVnrType", "ExterQual", "ExterCond","Foundation", "BsmtQual", "BsmtCond", "BsmtExposure", "BsmtFinType1", "Heating", "HeatingQC", "CentralAir","Electrical", "Functional", "GarageType", "GarageCond", "SaleCondition", "KitchenQual"), as.factor)
orderPrice <- orderPrice %>% mutate_at(c('MasVnrArea', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'BsmtFinSF1', 'TotalBsmtSF', 'X1stFlrSF', 'X2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'SalePrice'), as.numeric)

orderPrice$Clasificacion[orderPrice$SalePrice <= 139000] <- 'Economica'

orderPrice$Clasificacion[orderPrice$SalePrice > 139000 & orderPrice$SalePrice <= 189893 ] <- 'Intermedia'

orderPrice$Clasificacion[orderPrice$SalePrice > 189893] <- 'Cara'

orderPrice <- orderPrice %>% mutate_at(c('MasVnrArea', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'BsmtFinSF1', 'TotalBsmtSF', 'X1stFlrSF', 'X2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'SalePrice'), scale)
```

Fueron retiradas las variables que no tienen relación con la variable respuesta, así como aquellas con altas cantidades de NA's. Todas las variables categóricas fueron convertidas en factores y las numéricas fueron normalizadas. Además, fue agregada una variable categórica que representa el rango de precio en el que se encuentra cada una de las casas, esta es nuestra variable de interés.

## Muestreo

Muestreo estratificado

```{r dividir}
# COnvertir en factores
orderPrice <- orderPrice%>%mutate_at(c("Clasificacion"),as.factor)
set.seed(456)
economicas <- orderPrice[orderPrice$Clasificacion == 'Economica',]
intermedias <- orderPrice[orderPrice$Clasificacion == 'Intermedia',]
caras <- orderPrice[orderPrice$Clasificacion == 'Cara',]

filasCasasE <- sample(nrow(economicas), nrow(economicas)*0.7)
filasCasasI <- sample(nrow(intermedias), nrow(intermedias)*0.7)
filasCasasC <- sample(nrow(caras), nrow(caras)*0.7)

train <- rbind(economicas[filasCasasE,], intermedias[filasCasasI,], caras[filasCasasC,])
test <- rbind(economicas[-filasCasasE,], intermedias[-filasCasasI,], caras[-filasCasasC,])
```

## Generación de los modelos

```{r svm}
modeloSVM_1<-svm(Clasificacion~., data=train, cost=2^-5, kernel="linear")
modeloSVM_2<-svm(Clasificacion~., data=train, cost=0.5, kernel="polynomial", degree = 4, coef = 1)
modeloSVM_3<-svm(Clasificacion~., data=train, gamma=2^-5, kernel="radial")
modeloSVM_4<-svm(Clasificacion~., data=train, gamma=2^1, kernel="radial")

modeloSVM_1$fitted

summary(modeloSVM_1)
summary(modeloSVM_2)
summary(modeloSVM_3)
summary(modeloSVM_4)
```

## Predicciones

```{r predict}
prediccion1 <- predict(modeloSVM_1, newdata = test[,-58])
prediccion2 <- predict(modeloSVM_2, newdata = test[,-58])
prediccion3 <- predict(modeloSVM_3, newdata = test[,-58])
prediccion4 <- predict(modeloSVM_4, newdata = test[,-58])
```

## Matrices de confusión

```{r conf_matrix}
confusionMatrix(test[complete.cases(test), 58], prediccion1)
confusionMatrix(test[complete.cases(test), 58], prediccion2)
confusionMatrix(test[complete.cases(test), 58], prediccion3)
confusionMatrix(test[complete.cases(test), 58], prediccion4)

#Gr[afica predicción 1
ytest <- test[complete.cases(test), 58]
plot(prediccion1 , col="green",density=20,angle=135)
plot(ytest, col="blue",density=20,angle=45,add=TRUE, beside = TRUE)
legend("bottom",
c("Predicción del modelo","Datos reales"),
fill=c("green","blue"))

#Gráfica predicción 2
plot(prediccion2 , col="green",density=20,angle=135)
plot(ytest, col="blue",density=20,angle=45,add=TRUE, beside = TRUE)
legend("bottom",
c("Predicción del modelo","Datos reales"),
fill=c("green","blue"))

#Gráfica predicción 3
plot(prediccion3 , col="green",density=20,angle=135)
plot(ytest, col="blue",density=20,angle=45,add=TRUE, beside = TRUE)
legend("bottom",
c("Predicción del modelo","Datos reales"),
fill=c("green","blue"))

#Gráfica predicción 4
plot(prediccion4 , col="green",density=20,angle=135)
plot(ytest, col="blue",density=20,angle=45,add=TRUE, beside = TRUE)
legend("bottom",
c("Predicción del modelo","Datos reales"),
fill=c("green","blue"))

```

Tomando en cuenta la exactitud de cada uno de los modelos anteriores, podemos concluir que los mejores fueron el modelo lineal y el polinomial, pues cada uno logró explicar más del 80% de la variabilidad. Sin embargo, como podemos apreciar en los resultados de las matrices, todos los modelos cuentan con algo de underfitting, con excepción del modelo 4, clasificando varias casas de las caras o económicas como intermedias. Consideramos que eso es lógico, ya que es el valor de en medio y el que más puede tener factores en común con los otros dos. Veamos en cambio como el modelo 4 tiene problemas de overfitting, como era de esperarse al colocar un c bastante elevado. Vemos entonces cómo clasificó a todas las casas como Caras, de modo que solo se ajusta al conjunto de entrenamiento. En este caso, en los primeros modelos se debría subir un poco el costo, sin embargo,m por el tipo de modelo, esto ayudaría más que todo en el modelo 3. En el caso del modelo 4 se debe realizar lo contrario

## Comparación con modelos anteriores

Veamos que, a diferencia del modelo 4, el cual es el peor generado hasta la fecha, estos modelos son los que mejor porcentaje han tenido, y comparativamente se han equivocado en menos casas. En mejor modelo que teníamos anteriormente era uno realizado con RandomForest, el cual tenía un accuracy del 82.04%. Veamos que todos los modelos del 1-3 presentan un accuracy del 84% o superior, y vemos también en las matrices y gráficas que no se equivocaron mucho en la predicción de las casas

## Modelo de regresión con SVM

```{r regresion_svm}
trainNum <- train[, c('MasVnrArea', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'BsmtFinSF1', 'TotalBsmtSF', 'X1stFlrSF', 'X2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'SalePrice')]
testNum <- test[, c('MasVnrArea', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'BsmtFinSF1', 'TotalBsmtSF', 'X1stFlrSF', 'X2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'SalePrice')]

msvmrt <- tune.svm(SalePrice~., data = trainNum, cost=c(0.01,0.1,0.5,1,5,10,16,20,32), kernel="linear")
summary(msvmrt$best.model)
prediccionR <- predict(msvmrt$best.model, newdata = testNum[, -26])

```

### Comparación con otros modelos

En cuestión de tiempo, este fue el que tardó más tiempo en encontrar el mejor modelo, sin embargo, para predecir, este logró tener un porcentaje de predicción más elevado que los otros, sin embargo, debemos considerar las variable sutilizadas en cada modelo.
